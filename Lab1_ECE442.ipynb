{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoonalee/Application/blob/main/Lab1_ECE442.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIttxWZg5D8S"
      },
      "source": [
        "# ECE 442 Network Science Analytics - Laboratory 1\n",
        "## Manipulating network graphs, introduction to NetworkX and PyTorch Geometric\n",
        "\n",
        "In this first laboratory we will work with a real dataset, generate a network graph and analyze it using the Python package **[NetworkX](https://networkx.org/)**. We will also introduce **[pandas](https://pandas.pydata.org/)**, an excellent library to load and process datasets efficiently. A third goal of this assigment is to start familiarizing ourselves with **[PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/)**, a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to network data.\n",
        "\n",
        "To this end, we will study the email graph of the Enron corporation. Emails exchanged among several Enron employees in the period between November 1998 and June 2002 were made publicly available during the federal investigation; for additional details about the Enron scandal see https://en.wikipedia.org/wiki/Enron_scandal.  The completed dataset can be accessed from http://www.cs.cmu.edu/~enron/. Here we will use a smaller and curated version of the email corpus (for instance, with the email body removed), which can be obtained from http://cis.jhu.edu/~parky/Enron/enron.html.\n",
        "\n",
        "For those of you who have never worked with the aforementioned libraries, we hope this laboratory will provide a useful first exposure and bring you up to speed with what you will need for the rest of the course. We ask you upload to Gradescope the answers to all the questions that follow in a report submitted as a single pdf file. You are welcome to explore and play with the data beyond what we ask; let us know what you find!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v5d66ux0r8x"
      },
      "source": [
        "### Network graph generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljqF2gmO54y3"
      },
      "outputs": [],
      "source": [
        "# load the libraries we will use\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWGrbfmQ4qKe"
      },
      "outputs": [],
      "source": [
        "# get the dataset (see http://cis.jhu.edu/~parky/Enron/enron.html for additional details)\n",
        "!wget https://www.fing.edu.uy/~bmarenco/files/enron/employees\n",
        "!wget https://www.fing.edu.uy/~bmarenco/files/enron/execs.email.linesnum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UjEEZHy50qR"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "df_mails = pd.read_csv('execs.email.linesnum', names=['time','from','to'], sep=' ')\n",
        "df_employees = pd.read_csv('employees', sep='\\t', names=['mail', 'name and more'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA0VzjMw7VlS"
      },
      "source": [
        "In the variable `df_mails` we store a pandas [`DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) with the id of the sender (`from` column) and recepient (`to`) of an email sent at a given timestamp (`time`). In addition, the email user account and other information from the employees are stored in the dataframe  `df_employees`. You can think of a dataframe as an indexed table, but pandas offers plenty of additional functionalities, some of which we will leverage to process the data and generate the network graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaR2uNLG-auM"
      },
      "outputs": [],
      "source": [
        "# compute the dates from the timestamp (in seconds from 1/1/1970)\n",
        "df_mails['date'] = pd.to_datetime(df_mails.time, unit='s')\n",
        "\n",
        "# strangely enough there are dates from 1979. Let's remove those.\n",
        "df_mails = df_mails[df_mails.date.dt.year>1980]\n",
        "\n",
        "df_mails.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiNIuXYP8umA"
      },
      "source": [
        "### Graph construction for the entire time horizon\n",
        "\n",
        "First we construct a network graph spanning all emails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAmW8c7kEIb7"
      },
      "outputs": [],
      "source": [
        "# count number of emails between a pair of users\n",
        "mails_exchanged = df_mails.groupby(['from', 'to']).count().reset_index()\n",
        "mails_exchanged.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpxWsTfAE65P"
      },
      "outputs": [],
      "source": [
        "# the columns \"time\" and \"date\" have the same information, so abrbitrarily change one to \"weight\" which I will use to define edge weights\n",
        "mails_exchanged.rename(columns={'time':'weight'}, inplace=True)\n",
        "mails_exchanged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2TZkz7OGEEK"
      },
      "outputs": [],
      "source": [
        "# and here is something nice: pandas can be interfaced with networkx.\n",
        "G = nx.from_pandas_edgelist(mails_exchanged, source='from', target='to', edge_attr='weight', create_using=nx.DiGraph)\n",
        "\n",
        "# remove self loops\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "# generating a graph visualization is easy...\n",
        "nx.draw_networkx(G)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrLXKPBT7RPx"
      },
      "outputs": [],
      "source": [
        "# ... but cannot see much, typical ball of yarn phenomena we encounter with large graphs.\n",
        "\n",
        "# so let's be a little bit more creative\n",
        "positions = nx.circular_layout(G)\n",
        "edges = G.edges()\n",
        "weights = np.array([G[u][v]['weight'] for u,v in edges])\n",
        "\n",
        "between_dict = nx.betweenness_centrality(G)\n",
        "between = np.array(list(between_dict.values()))\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "nx.draw_networkx_nodes(G, pos=positions, node_color=10*np.log(1+between/(np.min(between)+1e-9)), cmap='Blues')\n",
        "nx.draw_networkx_edges(G, alpha=0.1, width=np.log10(weights+1), pos=positions)\n",
        "nx.draw_networkx_labels(G, pos=positions, font_color='black')\n",
        "plt.title('Network graph of emails exchanged during the whole time period.\\n Edge width is proportional to the number of emails exchanged (log scale).\\n \\\n",
        "  Vertex color intensity is proportional to its betweeness centrality (log scale).', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVkzFblZaH2x"
      },
      "source": [
        "### Interfacing NetworkX with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiT906OPXkER"
      },
      "outputs": [],
      "source": [
        "# in addition to interfacing with pandas, NetworkX can work with NumPy and matrices\n",
        "\n",
        "# for instance, obtaining the adjacency matrix is as simple as this\n",
        "G_np = nx.to_numpy_array(G,nodelist=range(G.number_of_nodes()))\n",
        "# we plot it using seaborn\n",
        "sns.heatmap(np.log10(G_np+1), cmap='Greys')\n",
        "plt.show()\n",
        "# or we can exclusively focus on the connecitivity pattern...\n",
        "sns.heatmap(G_np>0, cmap='Greys')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sscNxoyVx4K"
      },
      "source": [
        "## Network analysis\n",
        "\n",
        "Now you should use the Networkx or NumPy APIs to compute various summary statistics of the network graph `G(V,E)`:\n",
        "\n",
        "\n",
        "1.   Number of directed edges (arcs) in the network, i.e., the number of unique ordered pairs $(u,v)\\in E$,\n",
        "where $u,v\\in V$.\n",
        "2.   Number of undirected edges in the network, i.e., the number of unique unordered pairs $(u,v)\\in E$,\n",
        "where $u,v\\in V$. (This means that if at least one of $(u,v)\\in E$ or $(v,u)\\in E$, you count the pair as a single undirected edge.)\n",
        "3.   Number of mutual arcs in the network, i.e., the number of pairs $(u,v)$, where $\\{(u,v),(v,u)\\}\\subseteq E$\n",
        "and $u,v\\in V$. (This means that if both $(u,v)\\in E$ and $(v,u)\\in E$, you count the pair as a mutual arc.)\n",
        "4.   Number of nodes with $d_v^{\\text{in}}=0$, and list the corresponding employee names.\n",
        "5.   Number of nodes with $d_v^{\\text{out}}=0$, and list the corresponding employee names.\n",
        "6.   Number of employees that have been contacted by 30 or more employees. Generate a new graph visualization and: (i) color these nodes in red; (ii) label these nodes with the corresponding employee names.  \n",
        "7.   Number of employees that have contacted 30 or more employees. Generate a new graph visualization and: (i) color these nodes in red; (ii) label these nodes with the corresponding employee names.\n",
        "8.   Histogram of vertex degrees (separate $d_v^{\\text{in}}$ and $d_v^{\\text{out}}$). You can for instance use the histplot tool in seaborn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZn1nm5CagbZ"
      },
      "source": [
        "## Dynamic (temporal) network analysis\n",
        "\n",
        "So far we have examined the entire dataset and ignored its temporal dimension. To bridge this gap, in this section we will carry out a simple dynamic network analysis to study how the graph changes across time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADMP8EEVXTZq"
      },
      "outputs": [],
      "source": [
        "# let's cluster emails per week, so we first check to which week a given email corresponds to and then we add it to df_mails\n",
        "df_mails['week'] = df_mails.date.dt.to_period('W')\n",
        "print(df_mails.head())\n",
        "\n",
        "# per week aggregation. This generates a GroupBy object over which we can iterate, and contains all data for each week\n",
        "grouped_week = df_mails.groupby('week')\n",
        "# list that will contain the weekly network graphs\n",
        "graphs = []\n",
        "# list that will contain the weeeks themselves. Come be used to identify timestamps down the road.\n",
        "weeks = []\n",
        "\n",
        "for week_id, mails_group in grouped_week:\n",
        "    # we basically repeated what we did for the entire graph, but on a per week basis.\n",
        "    # we will be storing the weekly graphs in a list. Arguably not the most efficient approach, but the dataset is not that large\n",
        "\n",
        "    # count number of emails between a pair of users this week\n",
        "    mails_exchanged = mails_group.groupby(['from', 'to']).count().reset_index()\n",
        "    # the columns have the same information, so abrbitrarily change one to \"weight\" which I will use to define edge weights\n",
        "    mails_exchanged.rename(columns={'week':'weight'}, inplace=True)\n",
        "    G = nx.from_pandas_edgelist(mails_exchanged, source='from', target='to', edge_attr='weight', create_using=nx.DiGraph)\n",
        "\n",
        "    # remove self loops\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "    # add the new graph to the list\n",
        "    graphs.append(G)\n",
        "    weeks.append(week_id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgyUT8NnsVoS"
      },
      "outputs": [],
      "source": [
        "# let's examine the temporal evolution of some simple summary statistcs\n",
        "\n",
        "num_nodes = [current_graph.number_of_nodes() for current_graph in graphs]\n",
        "num_arcs = [current_graph.number_of_edges() for current_graph in graphs]\n",
        "pd.DataFrame({'n_nodes':num_nodes, 'n_arcs':num_arcs}, index=weeks).plot(figsize=(12,6))\n",
        "plt.grid()\n",
        "plt.legend(['Number of nodes', 'Number of arcs'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuoDL6Vx3vvm"
      },
      "source": [
        "### Changes in the network graph\n",
        "9. Pick two node centrality measures of your choice (see e.g., Ch. 4 of E. Kolaczyk's book Statistical Analysis of Network Data, the [lecture slides on centrality](https://www.hajim.rochester.edu/ece/sites/gmateos/ECE442/Slides/block_3_descriptive_analysis_properties_part_c.pdf), or the [NetworkX documentation](https://networkx.org/documentation/stable/reference/algorithms/centrality.html)) and indicate who was the most central Enron employee each week according to each of these measures.  Compare your results with what you obtain for the \"entire\" graph (namely, the network constructed earlier using data for the whole time horizon).\n",
        "10. Experiment with a few graph-level summary statistics (e.g., number of nodes, edges, average degree, average clustering coefficient, or any other of your liking) and use them to identify some of the major events tied to the scandal (Figure 8 in https://arxiv.org/abs/1403.0989 has a very nice timeline that could help). Likely you should be able to spot the launch of Enron online and Stephen Cooper's ascent to the CEO role."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plUYGwb-oh0J"
      },
      "source": [
        "## Introduction to Pytorch Geometric (PyG)\n",
        "**[PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric)** is a Python library for deep learning on graphs, which provides the required functionatility to work with Graph Neural Networks (GNNs). The library is an extension of **[PyTorch](https://pytorch.org/)**, arguably the most widely adopted open source deep learning framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLfWs_xwoh0J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version is {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S33uGlepoh0K"
      },
      "outputs": [],
      "source": [
        "# install PyG for the working version of PyTorch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTHkIICqoh0K"
      },
      "source": [
        "PyG includes several network datasets in the package **[torch_geometric.datasets](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets)**. In this part of the laboratory we will work with a dataset that has become a *de facto* testbed for community detection algorithms, namely [**Zachary's karate club network**](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxjTi2vioh0K"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import KarateClub\n",
        "\n",
        "dataset = KarateClub()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRf8X-czoh0L"
      },
      "source": [
        "The dataset consists of a single network graph, each vertex has an associated vector in $\\mathbb{R}^{34}$ (a so-termed nodal *feature* vector), and nodes are partitioned in 4 classes. Let's examine some other network summary statistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz2j97_foh0M"
      },
      "outputs": [],
      "source": [
        "# focus on the first time (and only) graph\n",
        "data = dataset[0]\n",
        "\n",
        "print(data)\n",
        "print('==============================================================')\n",
        "\n",
        "# network charactersitics\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average degree: {(2*data.num_edges) / data.num_nodes:.2f}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Graph has self loops: {data.has_self_loops()}')\n",
        "print(f'Graph is undirected: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB_zV8q-oh0M"
      },
      "source": [
        "A graph in PyG by an object of type [`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data). Each of these objects has at least 5 attributes:\n",
        "- **`x`**: is a network-wide feature matrix associated to the vertices (that is, a matrix whose columns are the nodal feature vectors). It is an object of type [`tensor`](https://pytorch.org/docs/stable/tensors.html), torch's native type to store matrices (the equivalent to [`ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) in numpy).\n",
        "- **`edge_index`**: is the graph's connectivity matrix in [COO](https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)) format. This format is very useful to store and work with *sparse* matrices (those having a large number of zeros, here denoting non-edges). It only stores a list of nodes connected by edges, instead of storting the whole adjacency matrix.\n",
        "- **`y`**: is a matrix of nodal labels (for the Karate club, the matrix that encodes the class membership of each vetex).\n",
        "- **`train_mask`**: binary matrix indicating the subset of vertices that are part of the training set. This will be useful down the road when we e.g.,  build and train a GNN model for node classification.\n",
        "- **`edge_attr`**: is a network-wide feature matrix associated to the edges. Since the Karate club network is unweighted, the dataset has no edge features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebs9sGvkoh0M"
      },
      "outputs": [],
      "source": [
        "print('data.x')\n",
        "print('========================================')\n",
        "print(data.x)\n",
        "print('\\ndata.edge_index')\n",
        "print('=========================================')\n",
        "print(data.edge_index.t())\n",
        "print('\\ndata.y')\n",
        "print('=========================================')\n",
        "print(data.y)\n",
        "print('\\ndata.train_mask')\n",
        "print('=========================================')\n",
        "print(data.train_mask)\n",
        "print('\\ndata.edge_attr')\n",
        "print('=========================================')\n",
        "print(data.edge_attr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLEBY1ojoh0N"
      },
      "source": [
        "PyG offers a simple interface to convert a graph into NetworkX's format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPIVsaswoh0N"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import to_networkx\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "nx.draw_networkx(G,node_color=data.y,pos=nx.spring_layout(G, seed=42))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKK__9ZAoh0N"
      },
      "source": [
        "## Verify properties of the graph Laplacian\n",
        "The goal of the following questions is to empirically verify a few properties of the graph Laplacian matrix. In the **optional** exercise below, you are asked to mathematically establish those properties.\n",
        "\n",
        "11. Compute the graph Laplacian matrix $\\mathbf{L}$ for Zachary's karate club network. You are encouraged to use some suitable function from the subpackage [`torch_geometric.utils`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html).\n",
        "12. Check that $\\mathbf{L}$ has a 0 eigenvalue and verify that the vector of all ones $[1,1,\\dots,1]^\\top$ is the corresponding eigenvector. The subpackage [`torch.linalg`](https://pytorch.org/docs/stable/linalg.html) may be useful to that end.\n",
        "13. Corroborate that $\\mathbf{L}$ is a symmetric positive semidefinite matrix.\n",
        "14. Form a matrix $\\tilde{\\mathbf{B}}$ as described in Part 2 of the optional exercise below and verify that $\\mathbf{L}=\\tilde{\\mathbf{B}}\\tilde{\\mathbf{B}}^\\top$. You are encouraged to use the function [`networkx.incidence_matrix`](https://networkx.org/documentation/stable/reference/generated/networkx.linalg.graphmatrix.incidence_matrix.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional exercise for extra credit: prove some properties of the graph Laplacian\n",
        "\n",
        "Consider an undirected and unweighted network graph $G(V,E)$, with order $N_v:=|V|$, size $N_e:=|E|$, and adjacency matrix $\\mathbf{A}$. Let $\\mathbf{D}=\\text{diag}(d_1,\\ldots,d_{N_v})$ be the degree matrix and $\\mathbf{L}:=\\mathbf{D}-\\mathbf{A}$ the Laplacian of $G$.\n",
        "\n",
        "1. Verify that $\\mathbf{1}:=[1,\\ldots,1]^\\top$ is an eigenvector of $\\mathbf{L}$ with associated eigenvalue $0$.\n",
        "2. Despite $G$ being an undirected graph, consider assigning an arbitrary \"virtual\" orientation to each edge in $E$, i.e., for each edge pick\n",
        "one of its incident vertices as the \"head\" and the other as the \"tail\". Given these assignments, consider the *signed* incidence matrix $\\tilde{\\mathbf{B}}\\in\\{-1,0,1\\}^{N_v\\times N_e}$ with $i,j$-th entry given by\n",
        "$$\\tilde{\\mathbf{B}}_{ij} = \\left\\lbrace\n",
        "\\begin{array}{r l}\n",
        "1,& \\text{if vertex } i \\text{ is incident to edge } j \\text{ as a tail}\\\\\n",
        "-1,& \\text{if vertex } i \\text{ is incident to } j \\text{ as a head}\\\\\n",
        "0,& \\text{otherwise}\n",
        "\\end{array}\n",
        "\\right. .\n",
        "$$\n",
        "Prove that the Laplacian matrix can be factorized as $\\mathbf{L}=\\tilde{\\mathbf{B}}\\tilde{\\mathbf{B}}^\\top$.\n",
        "\n",
        "3. Consider an arbitrary vector $\\mathbf{x}=[x_1,\\ldots,x_{N_v}]^\\top\\in \\mathbb{R}^{N_v}$. Using the result in Part 2 or otherwise, show that the quadratic form\n",
        "$$\\mathbf{x}^\\top \\mathbf{L}\\mathbf{x} = \\sum_{(i,j) \\in E} (x_i-x_j)^2.$$\n",
        "Conclude that $\\mathbf{L}$ is a symmetric positive semi-definite matrix.\n",
        "\n",
        "\n",
        "4. Show that if $G$ is disconnected then $\\mathbf{L}$ is block diagonal, with each block corresponding to the Laplacian of a particular connected component in $G$. Argue that in this case the second smallest eigenvalue of $\\mathbf{L}$ necessarily vanishes, by showing that one can construct at least two linearly independent eigenvectors of $\\mathbf{L}$ with associated eigenvalue $0$."
      ],
      "metadata": {
        "id": "7sY2tZrFS5xm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0d-zG2Noh0O"
      },
      "source": [
        "# Acknowledgements\n",
        "\n",
        "An intial version of this Laboratory (in Spanish) was conceived and developed by colleagues from [Facultad de Ingenieria](https://www.fing.edu.uy) in Montevideo, Uruguay and myself, for the course **[Aprendizaje Autom√°tico para Datos en Grafos](https://eva.fing.edu.uy/course/view.php?id=1626&section=0)**.\n",
        "\n",
        "The first part in the section '**Introduction to PyTorch Geometric**' is based on [this notebook](https://colab.research.google.com/drive/16tqEHKOLUgYvXKx1V3blfYGpQb1_09MG?usp=sharing#scrollTo=bbny-iTO7NQN) from Stanford's course **[CS224W: Machine Learning with Graphs](http://web.stanford.edu/class/cs224w)**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}